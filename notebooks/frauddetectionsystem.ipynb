{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7082010,"sourceType":"datasetVersion","datasetId":2673949}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### üïµÔ∏è‚Äç‚ôÇÔ∏è Comprehensive Guide to Fraud Detection System Workflow\n\nThis summary encapsulates the workflow of a fraud detection system, detailing the steps from data loading and preprocessing to model training, evaluation, and outlier detection. It emphasizes the systematic approach to identifying fraud using machine learning techniques and advanced analytics, highlighting the integration of Random Forest and Local Outlier Factor (LOF) models for refined fraud detection and analysis.\n\n\nThis code outlines a process for loading, preprocessing, splitting, and evaluating data for a fraud detection system. It begins by loading data from a specified file path and preprocessing it, which includes encoding categorical columns. The data is then split based on the month, with earlier months used for training and later months for testing. A Random Forest Classifier is trained on the training set. The model's performance is evaluated by predicting fraud probabilities, selecting a threshold for classification based on a desired false positive rate, and calculating recall. Additionally, Local Outlier Factor (LOF) is applied to non-fraud cases to identify outliers. The process includes logging for each major step, saving the trained Random Forest and LOF models, and visualizing results through ROC curves, confusion matrices, LOF scores, and a classification report","metadata":{}},{"cell_type":"markdown","source":"### üì¶ Install Packages","metadata":{}},{"cell_type":"code","source":"!pip install loguru","metadata":{"execution":{"iopub.status.busy":"2024-02-22T04:26:06.069368Z","iopub.execute_input":"2024-02-22T04:26:06.069793Z","iopub.status.idle":"2024-02-22T04:26:21.719919Z","shell.execute_reply.started":"2024-02-22T04:26:06.069762Z","shell.execute_reply":"2024-02-22T04:26:21.718253Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: loguru in /opt/conda/lib/python3.10/site-packages (0.7.2)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### ‚öôÔ∏è Config","metadata":{}},{"cell_type":"code","source":"# config.py\nconfig = {\n    \"FILE_PATH\": '/kaggle/input/bank-account-fraud-dataset-neurips-2022/Variant I.csv',\n    \"LOG_FILE\": \"my_log.log\",\n    \"LOG_ROTATION\": \"10 MB\",\n    \"RANDOM_STATE\": 42,\n    \"N_NEIGHBORS\": 20,\n    \"CONTAMINATION\": 'auto',\n}\n","metadata":{"execution":{"iopub.status.busy":"2024-02-22T04:26:21.722564Z","iopub.execute_input":"2024-02-22T04:26:21.722959Z","iopub.status.idle":"2024-02-22T04:26:21.729592Z","shell.execute_reply.started":"2024-02-22T04:26:21.722914Z","shell.execute_reply":"2024-02-22T04:26:21.728435Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### üìö Import Libraries","metadata":{}},{"cell_type":"code","source":"from loguru import logger\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n\nimport pickle\n#from config import config  # Make sure to import config correctly\n\nlogger.add(config[\"LOG_FILE\"], rotation=config[\"LOG_ROTATION\"])  # Use config dictionary values\n","metadata":{"execution":{"iopub.status.busy":"2024-02-22T04:26:21.731306Z","iopub.execute_input":"2024-02-22T04:26:21.731724Z","iopub.status.idle":"2024-02-22T04:26:23.359269Z","shell.execute_reply.started":"2024-02-22T04:26:21.731688Z","shell.execute_reply":"2024-02-22T04:26:23.358113Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}]},{"cell_type":"markdown","source":"### üìä Utils Plots","metadata":{}},{"cell_type":"code","source":"def plot_roc_auc(y_test, predictions):\n    try:\n        fpr, tpr, _ = roc_curve(y_test, predictions)\n        roc_auc = auc(fpr, tpr)\n        plt.figure()\n        plt.plot(fpr, tpr, label='RF AUC = %0.2f' % roc_auc)\n        plt.plot([0, 1], [0, 1], 'k--')\n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0, 1.05])\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title('Receiver operating characteristic')\n        plt.legend(loc=\"lower right\")\n        plt.show()\n        logger.info(\"ROC/AUC plot generated successfully.\")\n    except Exception as e:\n        logger.error(f\"Error generating ROC/AUC plot: {e}\")\n\ndef plot_confusion_matrix(y_test, preds_binary):\n    try:\n        cm = confusion_matrix(y_test, preds_binary)\n        plt.figure(figsize=(5,5))\n        sns.heatmap(cm, annot=True, fmt=\"d\", linewidths=.5, cmap='Blues', square=True)\n        plt.xlabel('Predicted label')\n        plt.ylabel('True label')\n        plt.title('Confusion Matrix')\n        plt.show()\n        logger.info(\"Confusion matrix plotted successfully.\")\n    except Exception as e:\n        logger.error(f\"Error plotting confusion matrix: {e}\")\n\ndef plot_lof_scores(non_fraud_data, lof_scores):\n    try:\n        plt.figure()\n        plt.scatter(non_fraud_data.index, lof_scores, c='blue', label='LOF Score')\n        plt.xlabel('Sample Index')\n        plt.ylabel('LOF Score')\n        plt.title('LOF Scores for Non-Fraud Cases')\n        plt.legend()\n        plt.show()\n        logger.info(\"LOF scores scatter plot generated successfully.\")\n    except Exception as e:\n        logger.error(f\"Error generating LOF scores scatter plot: {e}\")\n        \n","metadata":{"execution":{"iopub.status.busy":"2024-02-22T04:26:23.362151Z","iopub.execute_input":"2024-02-22T04:26:23.362757Z","iopub.status.idle":"2024-02-22T04:26:23.376297Z","shell.execute_reply.started":"2024-02-22T04:26:23.362706Z","shell.execute_reply":"2024-02-22T04:26:23.375102Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### üïµÔ∏è‚Äç‚ôÇÔ∏è Fraud Detection System","metadata":{}},{"cell_type":"code","source":"#def load_and_preprocess_data(file_path, nrows=2000):\ndef load_and_preprocess_data(file_path,nrows=10000):\n    try:\n        data = pd.read_csv(file_path)\n        logger.info(\"Data loaded successfully.\")  # Use logger instead of logging\n        categorical_cols = ['payment_type', 'source', 'device_os', 'employment_status', 'housing_status']\n        for col in categorical_cols:\n            if col in data.columns:\n                data[col] = LabelEncoder().fit_transform(data[col])\n        logger.info(\"Categorical columns encoded.\")\n        return data\n    except Exception as e:\n        logger.error(f\"Error loading or preprocessing data: {e}\")\n        raise\n        \ndef split_data_by_month(data):\n    # Assuming 'month' is a column in your DataFrame indicating the month of each record\n    train_data = data[data[\"month\"] < 6].sample(frac=1, replace=False)\n    test_data = data[data[\"month\"] >= 6].sample(frac=1, replace=False)\n    return train_data, test_data\n\n\ndef evaluate_model(rf_model, X_test, y_test):\n    # Get model predictions\n    predictions = rf_model.predict_proba(X_test)[:, 1]\n    \n    # Obtain ROC curve\n    fprs, tprs, thresholds = metrics.roc_curve(y_test, predictions)\n    \n    # Select 5% FPR as threshold\n    threshold = thresholds[fprs == max(fprs[fprs < 0.05])][0]\n    recall = tprs[fprs == max(fprs[fprs < 0.05])][0]\n    \n    # Binarize predictions based on the selected threshold\n    preds_binary = (predictions > threshold).astype(int)\n    \n    logger.info(f\"Selected Threshold: {threshold}, Recall at 5% FPR: {recall}\")\n    \n    # Further steps for Aequitas or other analyses would go here\n    \n    return preds_binary, recall\n\ndef main():\n    try:\n        data = load_and_preprocess_data(config[\"FILE_PATH\"])  # Access FILE_PATH using config dictionary\n\n        #X = data.drop('fraud_bool', axis=1)\n        #y = data['fraud_bool']\n        #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=config[\"RANDOM_STATE\"])\n        \n        # Split data by month instead of using train_test_split\n        train_data, test_data = split_data_by_month(data)\n        #print(train_data)\n        #print(test_data)\n        \n        # Separate features and labels for training and testing sets\n        X_train = train_data.drop('fraud_bool', axis=1)\n        y_train = train_data['fraud_bool']\n        X_test = test_data.drop('fraud_bool', axis=1)\n        y_test = test_data['fraud_bool']\n\n        rf_model = RandomForestClassifier(random_state=config[\"RANDOM_STATE\"])\n        rf_model.fit(X_train, y_train)\n        logger.info(\"Random Forest model trained.\")\n        \n        preds_binary, recall = evaluate_model(rf_model, X_test, y_test)\n        \n        # Continue with any additional processing or logging\n        logger.info(\"Evaluation complete.\")\n\n        rf_predictions = rf_model.predict(X_test)\n        predictions_proba = rf_model.predict_proba(X_test)[:, 1]\n\n        \n        non_fraud_indices = np.where(rf_predictions == 0)[0]\n        non_fraud_data = X_test.iloc[non_fraud_indices]\n       \n\n        lof_model = LocalOutlierFactor(n_neighbors=config[\"N_NEIGHBORS\"], contamination=config[\"CONTAMINATION\"])\n        lof_predictions = lof_model.fit_predict(non_fraud_data)\n        lof_scores = -lof_model.negative_outlier_factor_\n        \n        \n    \n        plot_roc_auc(y_test, predictions_proba, ax=axs[0, 0])\n        plot_confusion_matrix(y_test, preds_binary, ax=axs[0, 1])\n        plot_lof_scores(non_fraud_data, lof_scores, ax=axs[1, 0])\n\n        classification_text = \"Classification Report:\\n\" + str(classification_report(y_test, preds_binary))\n        classification_text\n        \n        logger.info(\"LOF model applied to non-fraud cases.\")\n\n        with open('random_forest_model.pkl', 'wb') as file:\n            pickle.dump(rf_model, file)\n        logger.info(\"Random Forest model saved.\")\n        \n        with open('lof_model_config.pkl', 'wb') as file:\n            pickle.dump(lof_model, file)\n        logger.info(\"LOF model configuration saved.\")\n\n        logger.info(\"Processing complete.\")\n    except Exception as e:\n        logger.error(f\"Error in main processing: {e}\")\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-22T04:38:33.869284Z","iopub.execute_input":"2024-02-22T04:38:33.869732Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[32m2024-02-22 04:38:38.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_and_preprocess_data\u001b[0m:\u001b[36m5\u001b[0m - \u001b[1mData loaded successfully.\u001b[0m\n\u001b[32m2024-02-22 04:38:39.885\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_and_preprocess_data\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mCategorical columns encoded.\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}